{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "#\n",
    "from sklearn.datasets import load_iris, fetch_20newsgroups, load_boston,fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load直接加载的内存的，数据集比较小，并不会保存到本地磁盘\n",
    "fetch数据集比较大，下载下来后会存在本地磁盘，下一次就不会再连接sklearn的服务器\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_iris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#鸢尾花数据集，查看特征，目标，样本量\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m li \u001B[38;5;241m=\u001B[39m \u001B[43mload_iris\u001B[49m()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m获取特征值\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(li\u001B[38;5;241m.\u001B[39mdata))\u001B[38;5;66;03m#\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'load_iris' is not defined"
     ]
    }
   ],
   "source": [
    "#鸢尾花数据集，查看特征，目标，样本量\n",
    "\n",
    "li = load_iris()\n",
    "\n",
    "print(\"获取特征值\")\n",
    "print(type(li.data))#\n",
    "print('-' * 50)\n",
    "print(li.data[0:3])# 前三个样本特征值\n",
    "print('-' * 50)\n",
    "print(li.data.shape) # 150个样本，4个特征,一般看shape\n",
    "print(\"目标值\")\n",
    "print(li.target) # 目标值\n",
    "print('-' * 50)\n",
    "print(li.DESCR) # 数据集描述\n",
    "print('-' * 50)\n",
    "print(li.feature_names)  # 重点,特征名字\n",
    "print('-' * 50)\n",
    "print(li.target_names) # 目标名字\n",
    "print('-' * 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 注意返回值, 训练集 train  x_train, y_train        测试集  test   x_test, y_test，顺序千万别搞错了\n",
    "# 默认是乱序的,random_state为了确保两次的随机策略一致，就会得到相同的随机数据，往往会带上\n",
    "x_train, x_test, y_train, y_test = train_test_split(li.data, li.target, test_size=0.25, random_state=1)\n",
    "\n",
    "print(\"训练集特征值和目标值：\", x_train, y_train)\n",
    "print(\"训练集特征值shape\", x_train.shape)\n",
    "\n",
    "print(\"测试集特征值和目标值：\", x_test, y_test)\n",
    "print(\"测试集特征值shape\", x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "150*0.25"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 下面是比较大的数据，需要下载一会，20类新闻\n",
    "#subset代表下载的数据集类型，默认是train，只有训练集\n",
    "news = fetch_20newsgroups(subset='all', data_home='data')\n",
    "# print(news.feature_names)  #这个数据集是没有的\n",
    "# print(news.DESCR)\n",
    "print('第一个样本')\n",
    "print(news.data[0])\n",
    "print('特征类型')\n",
    "print(type(news.data))\n",
    "print('-' * 50)\n",
    "print(news.target[0])\n",
    "print('-' * 50)\n",
    "print(len(news.data))\n",
    "print('新闻所有的标签')\n",
    "print(news.target)\n",
    "print('-' * 50)\n",
    "print(min(news.target), max(news.target))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#因为新版本sklearn去掉了 这个数据集，不再讲解\n",
    "# 接着来看回归的数据,是波士顿房价\n",
    "# lb = load_boston()\n",
    "#\n",
    "# print(\"获取特征值\")\n",
    "# print(lb.data[0])  #第一个样本特征值\n",
    "# print(lb.data.shape)\n",
    "# print('-' * 50)\n",
    "# print(\"目标值\")\n",
    "# print(lb.target)\n",
    "# print('-' * 50)\n",
    "# print(lb.DESCR)\n",
    "# print('-' * 50)\n",
    "# print(lb.feature_names)\n",
    "# print('-' * 50)\n",
    "# 回归问题没这个,打印这个会报错\n",
    "# print(lb.target_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "house=fetch_california_housing(data_home='data')\n",
    "print(\"获取特征值\")\n",
    "print(house.data[0])  #第一个样本特征值\n",
    "print('样本的形状')\n",
    "print(house.data.shape)\n",
    "print('-' * 50)\n",
    "print(\"目标值\")\n",
    "print(house.target)\n",
    "print('-' * 50)\n",
    "print(house.DESCR)\n",
    "print('-' * 50)\n",
    "print(house.feature_names)\n",
    "print('-' * 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 分类估计器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.sqrt(15*15+14*14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# K近邻\n",
    "\"\"\"\n",
    "K-近邻预测用户签到位置\n",
    ":return:None\n",
    "\"\"\"\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"./data/FBlocation/train.csv\")\n",
    "\n",
    "print(data.head(10))\n",
    "print(data.shape)\n",
    "# 处理数据\n",
    "# 1、缩小数据,查询数据,为了减少计算时间\n",
    "data = data.query(\"x > 1.0 &  x < 1.25 & y > 2.5 & y < 2.75\")\n",
    "\n",
    "# 处理时间的数据\n",
    "time_value = pd.to_datetime(data['time'], unit='s')\n",
    "\n",
    "print(time_value)  #最大时间是1月10号"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 把日期格式转换成 字典格式，把年，月，日，时，分，秒转换为字典格式，\n",
    "time_value = pd.DatetimeIndex(time_value)\n",
    "#\n",
    "print('-' * 50)\n",
    "print(time_value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('-' * 50)\n",
    "# 构造一些特征，执行的警告是因为我们的操作是复制，loc是直接放入\n",
    "print(type(data))\n",
    "# data['day'] = time_value.day\n",
    "# data['hour'] = time_value.hour\n",
    "# data['weekday'] = time_value.weekday\n",
    "#日期，是否是周末，小时对于个人行为的影响是较大的,所以才做下面的处理\n",
    "data.insert(data.shape[1], 'day', time_value.day) #data.shape[1]是代表插入到最后的意思\n",
    "data.insert(data.shape[1], 'hour', time_value.hour)\n",
    "data.insert(data.shape[1], 'weekday', time_value.weekday)\n",
    "\n",
    "#\n",
    "# 把时间戳特征删除\n",
    "data = data.drop(['time'], axis=1)\n",
    "print('-' * 50)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#星期天，实际weekday的值是6\n",
    "per = pd.Period('2023-07-13 22:00', 'H')\n",
    "per.weekday"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#观察数据，看下是否有异常值\n",
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 把签到数量少于n个目标位置删除，place_id是标签，即目标值\n",
    "place_count = data.groupby('place_id').count()\n",
    "place_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "place_count['x'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 把index变为0,1,2，3,4,5,6这种效果，从零开始排，原来的index是row_id\n",
    "#只选择去的人大于3的数据，认为1,2,3的是噪音，这个地方去的人很少，不用推荐给其他人\n",
    "tf = place_count[place_count.row_id > 3].reset_index()\n",
    "tf  #剩余的签到地点"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 根据设定的地点目标值，对原本的样本进行过滤\n",
    "#isin可以过滤某一列要在一组值\n",
    "data = data[data['place_id'].isin(tf.place_id)]\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 取出数据当中的特征值和目标值\n",
    "y = data['place_id']\n",
    "# 删除目标值，保留特征值，\n",
    "x = data.drop(['place_id'], axis=1)\n",
    "# 删除无用的特征值\n",
    "x = x.drop(['row_id'], axis=1)\n",
    "print(x.shape)\n",
    "print(x.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 进行数据的分割训练集合测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "\n",
    "# 特征工程（标准化）,下面3行注释，一开始我们不进行标准化，看下效果，目标值要不要标准化？\n",
    "std = StandardScaler()\n",
    "# #\n",
    "# # # 对测试集和训练集的特征值进行标准化,服务于knn fit\n",
    "x_train = std.fit_transform(x_train)\n",
    "# # transform返回的是copy，不在原有的输入对象中去修改\n",
    "# print(id(x_test))\n",
    "print(std.mean_)\n",
    "print(std.var_)\n",
    "x_test = std.transform(x_test)  #transfrom不再进行均值和方差的计算，是在原有的基础上去标准化\n",
    "print('-' * 50)\n",
    "# print(id(x_test))\n",
    "print(std.mean_)\n",
    "print(std.var_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 进行算法流程 # 超参数，可以通过设置n_neighbors=5，来调整结果好坏\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# # fit， predict,score，训练\n",
    "knn.fit(x_train, y_train)\n",
    "# # #\n",
    "# # # 得出预测结果\n",
    "y_predict = knn.predict(x_test)\n",
    "# #\n",
    "print(\"预测的目标签到位置为：\", y_predict)\n",
    "# # #\n",
    "# # # # 得出准确率\n",
    "print(\"预测的准确率:\", knn.score(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(max(time_value))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#网格搜索时讲解\n",
    "# # 构造一些参数的值进行搜索\n",
    "param = {\"n_neighbors\": [3, 5, 10, 12, 15],'weights':['uniform', 'distance']}\n",
    "#\n",
    "# 进行网格搜索，cv=3是3折交叉验证，用其中2折训练，1折验证\n",
    "gc = GridSearchCV(knn, param_grid=param, cv=3)\n",
    "\n",
    "gc.fit(x_train, y_train)  #你给它的x_train，它又分为训练集，验证集\n",
    "\n",
    "# 预测准确率，为了给大家看看\n",
    "print(\"在测试集上准确率：\", gc.score(x_test, y_test))\n",
    "\n",
    "print(\"在交叉验证当中最好的结果：\", gc.best_score_)\n",
    "\n",
    "print(\"选择最好的模型是：\", gc.best_estimator_)\n",
    "\n",
    "print(\"每个超参数每次交叉验证的结果：\", gc.cv_results_)\n",
    "gc.cv_results_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "朴素贝叶斯进行文本分类\n",
    ":return: None\n",
    "\"\"\"\n",
    "news = fetch_20newsgroups(subset='all', data_home='data')\n",
    "\n",
    "print(len(news.data))  #样本数，包含的特征\n",
    "print('-'*50)\n",
    "print(news.data[0]) #第一个样本 特征\n",
    "print('-'*50)\n",
    "print(news.target) #标签\n",
    "print(np.unique(news.target))\n",
    "print(news.target_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('-'*50)\n",
    "# 进行数据分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25, random_state=1)\n",
    "\n",
    "# 对数据集进行特征抽取\n",
    "tf = TfidfVectorizer()\n",
    "\n",
    "# 以训练集当中的词的列表进行每篇文章重要性统计['a','b','c','d']\n",
    "x_train = tf.fit_transform(x_train)\n",
    "#针对特征内容，可以自行打印\n",
    "print(len(tf.get_feature_names()))\n",
    "print(tf.get_feature_names()[70000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tf.get_feature_names()[0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "x_test = tf.transform(x_test)  #特征数目不发生改变\n",
    "print(len(tf.get_feature_names()))\n",
    "# 进行朴素贝叶斯算法的预测,alpha是拉普拉斯平滑系数，分子和分母加上一个系数，分母加alpha*特征词数目\n",
    "mlt = MultinomialNB(alpha=1.0)\n",
    "\n",
    "print(x_train.toarray())\n",
    "# 训练\n",
    "mlt.fit(x_train, y_train)\n",
    "end=time.time()\n",
    "end-start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "y_predict = mlt.predict(x_test)\n",
    "\n",
    "print(\"预测的文章类别为：\", y_predict)\n",
    "\n",
    "# 得出准确率,这个是很难提高准确率，为什么呢？\n",
    "print(\"准确率为：\", mlt.score(x_test, y_test))\n",
    "end=time.time()\n",
    "end-start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 目前这个场景我们不需要召回率，support是真实的为那个类别的有多少个样本\n",
    "print(\"每个类别的精确率和召回率：\", classification_report(y_test, y_predict,\n",
    "                                             target_names=news.target_names))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 把0-19总计20个分类，变为0和1\n",
    "# 5是可以改为0到19的\n",
    "y_test1 = np.where(y_test == 5, 1, 0)\n",
    "print(y_test1.sum())\n",
    "y_predict1 = np.where(y_predict == 5, 1, 0)\n",
    "print(y_predict1.sum())\n",
    "# roc_auc_score的y_test只能是二分类,针对多分类如何计算AUC\n",
    "print(\"AUC指标：\", roc_auc_score(y_test1, y_predict1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del news\n",
    "del x_train\n",
    "del x_test\n",
    "del y_test\n",
    "del y_predict\n",
    "del tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 决策树\n",
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.log2(1/32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "1 / 2 * np.log2(1 /2) + 1 / 2 * np.log2(1 /2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "1 / 3 * np.log2(1 / 3) + 2 / 3 * np.log2(2 / 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "决策树对泰坦尼克号进行预测生死\n",
    ":return: None\n",
    "\"\"\"\n",
    "# 获取数据\n",
    "titan = pd.read_csv(\"./data/titanic.txt\")\n",
    "titan.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 处理数据，找出特征值和目标值\n",
    "x = titan[['pclass', 'age', 'sex']]\n",
    "\n",
    "y = titan['survived']\n",
    "print(x.info())  # 用来判断是否有空值\n",
    "x.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 一定要进行缺失值处理,填为均值\n",
    "x['age'].fillna(x['age'].mean(), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 分割数据集到训练集合测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=4)\n",
    "print(x_train.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#性别是女性的数量\n",
    "x_train[x_train['sex'] == 'female'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#查看未存活的人的数量\n",
    "y_train[y_train == 0].count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x_train.to_dict(orient=\"records\")\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 进行处理（特征工程）特征-》类别-》one_hot编码\n",
    "dict = DictVectorizer(sparse=False)\n",
    "\n",
    "# 这一步是对字典进行特征抽取,to_dict可以把df变为字典，records代表列名变为键\n",
    "x_train = dict.fit_transform(x_train.to_dict(orient=\"records\"))\n",
    "print(type(x_train))\n",
    "print(dict.get_feature_names())\n",
    "print('-' * 50)\n",
    "x_test = dict.transform(x_test.to_dict(orient=\"records\"))\n",
    "print(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 用决策树进行预测，修改max_depth试试\n",
    "dec = DecisionTreeClassifier()\n",
    "\n",
    "#训练\n",
    "dec.fit(x_train, y_train)\n",
    "\n",
    "# 预测准确率\n",
    "print(\"预测的准确率：\", dec.score(x_test, y_test))\n",
    "\n",
    "# 导出决策树的结构\n",
    "export_graphviz(dec, out_file=\"tree.dot\",\n",
    "                feature_names=['年龄', 'pclass=1st', 'pclass=2nd', 'pclass=3rd', '女性', '男性'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#调整决策树的参数\n",
    "# 分割数据集到训练集合测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=4)\n",
    "# 进行处理（特征工程）特征-》类别-》one_hot编码\n",
    "dict = DictVectorizer(sparse=False)\n",
    "\n",
    "# 这一步是对字典进行特征抽取\n",
    "x_train = dict.fit_transform(x_train.to_dict(orient=\"records\"))\n",
    "x_test = dict.transform(x_test.to_dict(orient=\"records\"))\n",
    "\n",
    "# print(x_train)\n",
    "# # 用决策树进行预测，修改max_depth为10，发现提升了\n",
    "dec = DecisionTreeClassifier(max_depth=10,min_impurity_decrease=0.01)\n",
    "\n",
    "dec.fit(x_train, y_train)\n",
    "#\n",
    "# # 预测准确率\n",
    "print(\"预测的准确率：\", dec.score(x_test, y_test))\n",
    "#\n",
    "# # 导出决策树的结构\n",
    "export_graphviz(dec, out_file=\"tree1.dot\",\n",
    "                feature_names=dict.get_feature_names())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////\n",
    "# ////////////////////////////////////////////////////////"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 随机森林进行预测 （超参数调优），n_jobs充分利用多核的一个参数\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "# 120, 200, 300, 500, 800, 1200,n_estimators森林中决策树的数目，也就是分类器的数目\n",
    "# max_samples  是最大样本数\n",
    "#bagging类型\n",
    "param = {\"n_estimators\": [1500,2000, 5000], \"max_depth\": [2, 3, 5, 8, 15, 25]}\n",
    "\n",
    "# 网格搜索与交叉验证\n",
    "gc = GridSearchCV(rf, param_grid=param, cv=3)\n",
    "\n",
    "gc.fit(x_train, y_train)\n",
    "\n",
    "print(\"准确率：\", gc.score(x_test, y_test))\n",
    "\n",
    "print(\"查看选择的参数模型：\", gc.best_params_)\n",
    "\n",
    "print(\"选择最好的模型是：\", gc.best_estimator_)\n",
    "\n",
    "print(\"每个超参数每次交叉验证的结果：\", gc.cv_results_)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}